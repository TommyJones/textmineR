% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/topic_modeling_core.R
\name{update.lda_topic_model}
\alias{update.lda_topic_model}
\title{Update a Latent Dirichlet Allocation topic model}
\usage{
\method{update}{lda_topic_model}(object, dtm, additional_k = 0,
  phi_as_prior = FALSE, iterations = NULL, burnin = -1,
  optimize_alpha = FALSE, calc_likelihood = FALSE,
  calc_coherence = FALSE, calc_r2 = FALSE, return_data = FALSE, ...)
}
\arguments{
\item{object}{a fitted object of class \code{lda_topic_model}.}

\item{dtm}{A document term matrix or term co-occurrence matrix of class dgCMatrix.}

\item{additional_k}{Integer number of topics to add, defaults to 0.}

\item{phi_as_prior}{Logical. Do you want to replace \code{beta} with \code{phi}
from the previous model as the prior for words over topics?}

\item{iterations}{Integer number of iterations for the Gibbs sampler to run.}

\item{burnin}{Integer number of burnin iterations. If \code{burnin} is greater than -1,
the resulting "phi" and "theta" matrices are an average over all iterations
greater than \code{burnin}.}

\item{optimize_alpha}{Logical. Do you want to optimize alpha every iteration?
Defaults to \code{FALSE}. See 'details' of documentation for
\code{\link[textmineR]{FitLdaModel}}for more information.}

\item{calc_likelihood}{Logical. Do you want to calculate the log likelihood every iteration?
Useful for assessing convergence. Defaults to \code{FALSE}.}

\item{calc_coherence}{Logical. Do you want to calculate probabilistic coherence of topics
after the model is trained? Defaults to \code{FALSE}. This calls
\code{\link[textmineR]{CalcProbCoherence}}.}

\item{calc_r2}{Logical. Do you want to calculate R-squared after the model is trained?
Defaults to \code{FALSE}. This calls \code{\link[textmineR]{CalcTopicModelR2}}.}

\item{return_data}{Logical. Do you want \code{dtm} returned as part of the model object?}

\item{...}{Other arguments to be passed to \code{\link[textmineR]{TmParallelApply}}}
}
\value{
Returns an S3 object of class c("lda_topic_model").
}
\description{
Update an LDA model using collapsed Gibbs sampling.
}
\details{
prior + counts vs. counts only. Vocab alignment + uniform prior over new words. 
         Adding additional topics. works best with significant vocab overlap
}
\examples{
\dontrun{
# load a document term matrix
d1 <- nih_sample_dtm[1:50,]

d2 <- nih_sample_dtm[51:100,]

# fit a model
m <- FitLdaModel(d1, k = 10, 
                 iterations = 200, burnin = 175,
                 optimize_alpha = TRUE, 
                 calc_likelihood = FALSE,
                 calc_coherence = TRUE,
                 calc_r2 = FALSE)

# update an existing model by adding documents
m2 <- update(object = m,
             dtm = rbind(d1, d2),
             iterations = 200,
             burnin = 175)
             
# use an old model as a prior for a new model
m3 <- update(object = m,
             dtm = d2, # new documents only
             iterations = 200,
             burnin = 175)
             
# add topics while updating a model by adding documents
m4 <- update(object = m,
             dtm = rbind(d1, d2),
             additional_k = 3,
             iterations = 200,
             burnin = 175)
             
# add topics to an existing model
m5 <- update(object = m,
             dtm = d1, # this is the old data
             additional_k = 3,
             iterations = 200,
             burnin = 175)

}
}
